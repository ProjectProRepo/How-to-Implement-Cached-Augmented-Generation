{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711,
          "referenced_widgets": [
            "cc09ee7d5c0046d99eeeff69afcbb0c6",
            "e3f03d733f4c46f29e869271763280d9",
            "2cb90767f05d4699beb1a7f46701d7c1",
            "3068998e80a84a31a225129d199062f0",
            "8a13788ee86b4e8cb4c2e30a6b0fe156",
            "cc085b6101ee46d2a44cebc686d9f3cc",
            "370f9c9ff07f4b6093c39148ab58b695",
            "aad2669be6ad47118c7e2ed05d71e76e",
            "a4bbdf05f69e4ea594a952f7a2bd4313",
            "b2f46f276d024ff8a816f18cdc79793e",
            "5138ce2b5f154363acaabf19be686412",
            "0d3358697f1b4062a8912c13daab967a",
            "5a1dbf3162ea45608cb7f354ff0e6e84",
            "d5f0bd0ea31c43459ce3f02f634698e6",
            "f6e6dc08385f4d299831606ceb588907",
            "103f9da0d96642ecab4b7c520789de7d",
            "f368adf558264f6a82378d9ec6ea329f",
            "0a3dbfdd7e064a68989d9fe219e00d90",
            "f77d3fd85603426d87b78abc07ef8bbd",
            "ed174f6edbf54fccbf1a1de0d43276b5"
          ]
        },
        "id": "roBigVRKuuFK",
        "outputId": "8f0bae18-b7f3-4fa0-b1d0-57456919deb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc09ee7d5c0046d99eeeff69afcbb0c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -U bitsandbytes transformers accelerate\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from transformers.cache_utils import DynamicCache\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()  # Login with your HF token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3L7bLLCuvqX"
      },
      "outputs": [],
      "source": [
        "# Choose any model you have access to (e.g. LLaMA 2)\n",
        "model_id = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "#model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "\n",
        "# Quantization config for 4-bit loading\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "5a21ed59cdd54849b23cff491691d69b",
            "4992c799b3b949f1a8ef687e9ee7ae65",
            "4c0bdab2d2e64df49fa38852084e325d",
            "c4d7dc0e41414d33b78d3871b22420bd",
            "f8302732a0004a8a8fcfee6f00a98c06",
            "2ce9f56870d04eb2a47d2f15164d008d",
            "5979745f22494223906024e94121d39a",
            "8baf61013dc14e1f804a30047dc4ca7e",
            "01a0b0cafc384b4396a86076a7367c0b",
            "e73dc398e3644a4a976b9dbc4972e63e",
            "1acbac50063f4717ac59c5da69105bac"
          ]
        },
        "id": "4aiMpUIiwQTA",
        "outputId": "0e3f069f-87ab-4e51-a831-62619da24e64"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a21ed59cdd54849b23cff491691d69b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWIMGN8LGG8D"
      },
      "outputs": [],
      "source": [
        "# Sample (random) knowledge base: Tech gadget recalls\n",
        "knowledge_base = \"\"\"\n",
        "Incident 1: Smartwatch Sync Issue\n",
        "Device: TechFit Pro Smartwatch\n",
        "Problem: Fails to sync with Android phones due to firmware bug.\n",
        "Fix: Firmware update version 2.1.4 resolved Bluetooth sync issues.\n",
        "\n",
        "Incident 2: Noise Cancelling Headphones Overheating\n",
        "Device: SoundBliss NC700\n",
        "Problem: Excessive heat during long use, especially when ANC is on.\n",
        "Fix: Manufacturer advised users to limit use, offered refunds.\n",
        "\n",
        "Incident 3: Fitness Band Step Miscount\n",
        "Device: FitRun 360\n",
        "Problem: Inaccurate step count, overestimates by 20–30%.\n",
        "Fix: Patch 1.0.5 released to fix accelerometer calibration.\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKG_TIUWGIrw"
      },
      "outputs": [],
      "source": [
        "# Cache the knowledge\n",
        "def preload_knowledge(knowledge):\n",
        "    input_ids = tokenizer.encode(knowledge, return_tensors=\"pt\").to(model.device)\n",
        "    cache = DynamicCache()\n",
        "    with torch.no_grad():\n",
        "        _ = model(input_ids=input_ids, use_cache=True, past_key_values=cache)\n",
        "    return cache\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6hAzlRLHVlr"
      },
      "outputs": [],
      "source": [
        "# Load the knowledge into KV cache\n",
        "kv_cache = preload_knowledge(knowledge_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZShBDMy0HV52"
      },
      "outputs": [],
      "source": [
        "# Generate answer based on cached knowledge\n",
        "def ask_question(question, kv_cache, max_new_tokens=100):\n",
        "    input_ids = tokenizer.encode(question, return_tensors=\"pt\").to(model.device)\n",
        "    output_ids = input_ids.clone()\n",
        "    next_token = input_ids\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_new_tokens):\n",
        "            outputs = model(\n",
        "                input_ids=next_token,\n",
        "                use_cache=True,\n",
        "                past_key_values=kv_cache\n",
        "            )\n",
        "            next_token_logits = outputs.logits[:, -1, :]\n",
        "            next_token = next_token_logits.argmax(dim=-1).unsqueeze(-1)\n",
        "\n",
        "            output_ids = torch.cat([output_ids, next_token], dim=-1)\n",
        "\n",
        "            if next_token.item() == tokenizer.eos_token_id:\n",
        "                break\n",
        "\n",
        "            # Update KV cache\n",
        "            kv_cache = outputs.past_key_values\n",
        "\n",
        "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcsnlMgTWFhx",
        "outputId": "625831b2-36c8-40da-e5bb-9d8eb35e7c0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "List all devices mentioned in the incidents. Just names.\n",
            "TechFit Pro Smartwatch\n",
            "SoundBliss NC700\n",
            "FitRun 360\n",
            "\n",
            "What was wrong with the TechFit Pro Smartwatch? Keep it brief. \n",
            "Firmware bug caused sync issues. \n",
            "\n",
            "What solution was offered for overheating headphones? \n",
            "Manufacturer advised users to limit use and offered refunds. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# General info prompt\n",
        "q1 = \"List all devices mentioned in the incidents. Just names.\"\n",
        "r1 = ask_question(q1, kv_cache)\n",
        "print(f\"{r1}\\n\")\n",
        "\n",
        "# Problem-focused prompt\n",
        "q2 = \"What was wrong with the TechFit Pro Smartwatch? Keep it brief.\"\n",
        "r2 = ask_question(q2, kv_cache)\n",
        "print(f\"{r2}\\n\")\n",
        "\n",
        "# Fix-focused prompt\n",
        "q3 = \"What solution was offered for overheating headphones?\"\n",
        "r3 = ask_question(q3, kv_cache)\n",
        "print(f\"{r3}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqeO2obUduRr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}